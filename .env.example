# === Ollama Configuration ===
# Modèle LLM à utiliser (doit être disponible dans Ollama)
OLLAMA_MODEL=gpt-oss:120b-cloud

# Clé API pour les modèles cloud (laisser vide pour les modèles locaux)
OLLAMA_API_KEY=votre_cle_api_ici

# URL du serveur Ollama (par défaut : http://localhost:11434)
# OLLAMA_BASE_URL=http://localhost:11434
