"""
Interface Streamlit pour le chatbot RAG de documents juridiques.
Point d'entr√©e de l'application.
"""
import streamlit as st
import time
import os
import shutil
from pathlib import Path

from rag_pipeline import RAGPipeline
from config import OLLAMA_MODEL, GROQ_MODEL, LLM_PROVIDER, DOCUMENTS_DIR


# === Configuration de la page ===
st.set_page_config(
    page_title="ü§ñ LexiBot",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded",
)

# === CSS personnalis√© ===
st.markdown("""
<style>
    /* En-t√™te principal */
    .main-header {
        background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%);
        padding: 1.5rem 2rem;
        border-radius: 12px;
        margin-bottom: 1.5rem;
        color: white;
        text-align: center;
    }
    .main-header h1 {
        margin: 0;
        font-size: 1.8rem;
        font-weight: 700;
    }
    .main-header p {
        margin: 0.3rem 0 0 0;
        opacity: 0.85;
        font-size: 0.95rem;
    }
    
    /* Cartes de stats */
    .stat-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 0.5rem;
    }
    .stat-card .number {
        font-size: 1.8rem;
        font-weight: 700;
    }
    .stat-card .label {
        font-size: 0.8rem;
        opacity: 0.9;
    }
    
    /* Sources */
    .source-card {
        background: #f8f9fa;
        border-left: 4px solid #667eea;
        padding: 0.8rem 1rem;
        margin: 0.5rem 0;
        border-radius: 0 8px 8px 0;
        font-size: 0.85rem;
    }
    .source-card .source-header {
        font-weight: 600;
        color: #1a1a2e;
        margin-bottom: 0.3rem;
    }
    .source-card .source-text {
        color: #555;
        font-style: italic;
    }
    
    /* Disclaimer */
    .disclaimer {
        background: #fff3cd;
        border: 1px solid #ffc107;
        border-radius: 8px;
        padding: 0.8rem 1rem;
        font-size: 0.8rem;
        color: #856404;
        margin-top: 1rem;
    }
    
    /* Sidebar style */
    [data-testid="stSidebar"] {
        background: linear-gradient(180deg, #1a1a2e 0%, #16213e 100%);
    }
    [data-testid="stSidebar"] * {
        color: #e0e0e0 !important;
    }
    [data-testid="stSidebar"] h1, [data-testid="stSidebar"] h2, [data-testid="stSidebar"] h3 {
        color: white !important;
    }
    
    /* Chat message styling */
    .stChatMessage {
        border-radius: 12px;
    }
</style>
""", unsafe_allow_html=True)


# === Initialisation du state ===
def init_session_state():
    """Initialise les variables de session Streamlit."""
    if "pipeline" not in st.session_state:
        st.session_state.pipeline = RAGPipeline()
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "indexed_files" not in st.session_state:
        st.session_state.indexed_files = []
    if "indexing_done" not in st.session_state:
        st.session_state.indexing_done = False

init_session_state()


# === Sidebar ===
with st.sidebar:
    st.markdown("## ü§ñ LexiBot")
    st.markdown("---")
    
    # Upload de fichiers
    st.markdown("### üìÑ Charger des documents")
    uploaded_files = st.file_uploader(
        "Glissez vos fichiers PDF ici",
        type=["pdf"],
        accept_multiple_files=True,
        help="Formats support√©s : PDF. Vous pouvez charger plusieurs fichiers."
    )
    
    # Bouton d'indexation
    if uploaded_files:
        if st.button("üöÄ Indexer les documents", use_container_width=True, type="primary"):
            with st.spinner("Indexation en cours..."):
                total_chunks = 0
                total_pages = 0
                
                for uploaded_file in uploaded_files:
                    # Sauvegarder le fichier temporairement
                    file_path = DOCUMENTS_DIR / uploaded_file.name
                    with open(file_path, "wb") as f:
                        f.write(uploaded_file.getbuffer())
                    
                    # Indexer
                    try:
                        stats = st.session_state.pipeline.index_pdf(str(file_path))
                        total_chunks += stats["chunks_crees"]
                        total_pages += stats["pages_extraites"]
                        
                        if uploaded_file.name not in st.session_state.indexed_files:
                            st.session_state.indexed_files.append(uploaded_file.name)
                        
                    except Exception as e:
                        st.error(f"Erreur avec {uploaded_file.name}: {str(e)}")
                
                st.session_state.indexing_done = True
                st.success(f"‚úÖ {total_pages} pages ‚Üí {total_chunks} chunks index√©s !")
    
    st.markdown("---")
    
    # Statistiques
    st.markdown("### üìä Statistiques")
    stats = st.session_state.pipeline.get_stats()
    
    col1, col2 = st.columns(2)
    with col1:
        st.markdown(
            f'<div class="stat-card">'
            f'<div class="number">{stats["total_chunks"]}</div>'
            f'<div class="label">Chunks index√©s</div>'
            f'</div>',
            unsafe_allow_html=True
        )
    with col2:
        st.markdown(
            f'<div class="stat-card">'
            f'<div class="number">{len(st.session_state.indexed_files)}</div>'
            f'<div class="label">Documents</div>'
            f'</div>',
            unsafe_allow_html=True
        )
    
    # Liste des fichiers index√©s
    if st.session_state.indexed_files:
        st.markdown("**Fichiers charg√©s :**")
        for f in st.session_state.indexed_files:
            st.markdown(f"üìé {f}")
    
    st.markdown("---")
    
    # Configuration
    st.markdown("### ‚öôÔ∏è Configuration")
    model_name = GROQ_MODEL if LLM_PROVIDER == "groq" else OLLAMA_MODEL
    provider_label = "‚òÅÔ∏è Groq" if LLM_PROVIDER == "groq" else "üñ•Ô∏è Ollama"
    st.markdown(f"**Provider :** `{provider_label}`")
    st.markdown(f"**Mod√®le LLM :** `{model_name}`")
    st.markdown(f"**Embeddings :** `{stats['embedding_model']}`")
    
    st.markdown("---")
    
    # R√©initialiser
    if st.button("üóëÔ∏è R√©initialiser la base", use_container_width=True):
        st.session_state.pipeline.reset()
        st.session_state.messages = []
        st.session_state.indexed_files = []
        st.session_state.indexing_done = False
        st.success("Base r√©initialis√©e !")
        st.rerun()


# === Zone principale ===
# En-t√™te
st.markdown(
    '<div class="main-header">'
    '<h1>ü§ñ LexiBot</h1>'
    '<p>Posez vos questions sur vos documents juridiques et repartez avec les id√©es plus claires</p>'
    '</div>',
    unsafe_allow_html=True
)

# Message d'accueil si pas de documents
if not st.session_state.indexing_done and stats["total_chunks"] == 0:
    st.info(
        "üëã **Bienvenue !** Commencez par charger un ou plusieurs fichiers PDF "
        "via la barre lat√©rale, puis cliquez sur **Indexer les documents**."
    )
    
    # Exemples de questions
    st.markdown("#### üí° Exemples de questions que vous pourrez poser :")
    cols = st.columns(2)
    with cols[0]:
        st.markdown(
            "- *Quelles sont les r√®gles pour le commerce √©lectronique ?*\n"
            "- *Quelles sanctions sont pr√©vues en cas d'infraction ?*"
        )
    with cols[1]:
        st.markdown(
            "- *Explique-moi l'article 15 comme si je n'y connaissais rien*\n"
            "- *Quels sont mes droits en mati√®re de donn√©es personnelles ?*"
        )

# Afficher l'historique des messages
for message in st.session_state.messages:
    with st.chat_message(message["role"], avatar="üßë‚Äçüíº" if message["role"] == "user" else "‚öñÔ∏è"):
        st.markdown(message["content"])
        
        # Afficher les sources si c'est une r√©ponse assistant
        if message["role"] == "assistant" and message.get("sources"):
            with st.expander(f"üìå Sources ({len(message['sources'])} extraits)", expanded=False):
                for i, source in enumerate(message["sources"], 1):
                    article = source.get("article", "")
                    chapitre = source.get("chapitre", "")
                    page = source.get("page", "")
                    pertinence = source.get("pertinence", "")
                    
                    header_parts = []
                    if article:
                        header_parts.append(article)
                    if chapitre:
                        header_parts.append(chapitre)
                    header = " | ".join(header_parts) if header_parts else f"Extrait {i}"
                    
                    st.markdown(
                        f'<div class="source-card">'
                        f'<div class="source-header">üìé {header} (p.{page}) ‚Äî {pertinence}</div>'
                        f'<div class="source-text">{source["texte"]}</div>'
                        f'</div>',
                        unsafe_allow_html=True
                    )

# Input de chat
# Patterns conversationnels qui ne n√©cessitent pas de recherche RAG
_CONVERSATIONAL_PATTERNS = {
    "merci", "merci beaucoup", "thanks", "thank you", "ok", "okay", "d'accord",
    "super", "parfait", "g√©nial", "cool", "top", "bien", "tr√®s bien", "excellent",
    "bonjour", "bonsoir", "salut", "hello", "hi", "hey", "coucou",
    "au revoir", "bye", "√† bient√¥t", "bonne journ√©e", "bonne soir√©e",
    "oui", "non", "je comprends", "compris", "c'est clair", "c'est not√©",
}

_CONVERSATIONAL_RESPONSES = {
    "greeting": "üëã Bonjour ! Posez-moi une question sur vos documents juridiques, je suis l√† pour vous aider.",
    "thanks": "üòä Avec plaisir ! N'h√©sitez pas si vous avez d'autres questions.",
    "farewell": "üëã √Ä bient√¥t ! Bonne continuation.",
    "acknowledge": "üëç D'accord ! Si vous avez d'autres questions, je suis l√†.",
}

def _detect_conversational(text: str) -> str | None:
    """D√©tecte si un message est conversationnel et retourne le type."""
    clean = text.strip().lower().rstrip("!?.‚Ä¶")
    if clean not in _CONVERSATIONAL_PATTERNS:
        return None
    if clean in {"bonjour", "bonsoir", "salut", "hello", "hi", "hey", "coucou"}:
        return "greeting"
    if clean in {"merci", "merci beaucoup", "thanks", "thank you"}:
        return "thanks"
    if clean in {"au revoir", "bye", "√† bient√¥t", "bonne journ√©e", "bonne soir√©e"}:
        return "farewell"
    return "acknowledge"

if prompt := st.chat_input("Pose ta question sur le num√©rique et tes droits..."):
    # V√©rifier qu'il y a des documents index√©s
    if stats["total_chunks"] == 0:
        st.warning("‚ö†Ô∏è Veuillez d'abord charger et indexer des documents via la barre lat√©rale.")
    else:
        # Afficher la question utilisateur
        with st.chat_message("user", avatar="üßë‚Äçüíº"):
            st.markdown(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        # V√©rifier si c'est un message conversationnel (pas besoin de RAG)
        conv_type = _detect_conversational(prompt)
        
        if conv_type:
            # R√©ponse directe sans appel API
            reply = _CONVERSATIONAL_RESPONSES[conv_type]
            with st.chat_message("assistant", avatar="‚öñÔ∏è"):
                st.markdown(reply)
            st.session_state.messages.append({
                "role": "assistant",
                "content": reply,
                "sources": [],
            })
        else:
            # G√©n√©rer la r√©ponse via le pipeline RAG
            with st.chat_message("assistant", avatar="‚öñÔ∏è"):
                with st.spinner("üîç Recherche dans les documents et g√©n√©ration de la r√©ponse..."):
                    result = st.session_state.pipeline.ask(prompt)
                
                st.markdown(result["answer"])
                
                # Afficher les sources
                if result["sources"]:
                    with st.expander(f"üìå Sources ({len(result['sources'])} extraits)", expanded=False):
                        for i, source in enumerate(result["sources"], 1):
                            article = source.get("article", "")
                            chapitre = source.get("chapitre", "")
                            page = source.get("page", "")
                            pertinence = source.get("pertinence", "")
                            
                            header_parts = []
                            if article:
                                header_parts.append(article)
                            if chapitre:
                                header_parts.append(chapitre)
                            header = " | ".join(header_parts) if header_parts else f"Extrait {i}"
                            
                            st.markdown(
                                f'<div class="source-card">'
                                f'<div class="source-header">üìé {header} (p.{page}) ‚Äî {pertinence}</div>'
                                f'<div class="source-text">{source["texte"]}</div>'
                                f'</div>',
                                unsafe_allow_html=True
                            )
            
            # Sauvegarder dans l'historique
            st.session_state.messages.append({
                "role": "assistant",
                "content": result["answer"],
                "sources": result["sources"],
            })

# Disclaimer
st.markdown("---")
st.markdown(
    '<div class="disclaimer">'
    '‚ö†Ô∏è <strong>Avertissement :</strong> Cet outil fournit des informations √† titre indicatif uniquement. '
    'Il ne constitue pas un conseil juridique professionnel. '
    'V√©rifiez toujours les informations avec un professionnel qualifi√© avant de prendre des d√©cisions.'
    '</div>',
    unsafe_allow_html=True
)
